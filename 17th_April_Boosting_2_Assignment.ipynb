{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Gradient Boosting Regression?"
      ],
      "metadata": {
        "id": "ZV24eJMNg0lP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:-\n",
        "\n",
        "Gradient Boosting Regression is a type of machine learning algorithm that is used for regression problems. It is a powerful technique that combines multiple weak regression models into a single, strong model. The basic idea behind gradient boosting regression is to iteratively add new models to the ensemble that correct the errors made by the previous models.\n",
        "\n",
        "In gradient boosting, each model in the ensemble is built by optimizing a cost function that measures the difference between the predicted values and the true values of the target variable. The optimization is performed using gradient descent, which involves iteratively adjusting the model parameters in the direction of steepest descent of the cost function.\n",
        "\n",
        "Gradient boosting regression is a popular technique for solving a variety of regression problems, such as predicting house prices, stock prices, and customer lifetime value. It is known for its ability to handle complex, non-linear relationships between the input features and the target variable, and for its high accuracy and robustness. However, it can be computationally expensive and may require careful tuning of hyperparameters to achieve optimal performance."
      ],
      "metadata": {
        "id": "H4QMleMHg3as"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Implement a simple gradient boosting algorithm from scratch using Python and NumPy. Use a\n",
        "simple regression problem as an example and train the model on a small dataset. Evaluate the model's\n",
        "performance using metrics such as mean squared error and R-squared."
      ],
      "metadata": {
        "id": "xRGXwl-ioiYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:-"
      ],
      "metadata": {
        "id": "a0Btjh-Hoi19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error"
      ],
      "metadata": {
        "id": "pZwK6J9XpX4p"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = make_regression(n_samples=1000,n_features=5,n_informative=3,random_state=42,shuffle=False)\n",
        "\n",
        "X.shape , y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOD-L5WDpca7",
        "outputId": "9d883b58-dbf4-4cbd-857f-002590ec3cdf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 5), (1000,))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
        "\n",
        "X_train.shape , X_test.shape , y_train.shape , y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAYaPVtYpint",
        "outputId": "b78c2478-f657-496b-add9-c13d7a5be222"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((750, 5), (250, 5), (750,), (250,))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb = GradientBoostingRegressor()\n",
        "gb.fit(X_train,y_train)\n",
        "y_pred = gb.predict(X_test)\n",
        "print(f\"R-squared : {r2_score(y_test,y_pred)}\")\n",
        "print(f\"Mean Square Error : {mean_squared_error(y_test,y_pred)}\")\n",
        "print(f\"Mean Absolute Error : {mean_absolute_error(y_test,y_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1lK6MpTpluv",
        "outputId": "66c8f835-b7f1-4db2-ae17-44779bad3463"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared : 0.9896457617058474\n",
            "Mean Square Error : 29.049268596420507\n",
            "Mean Absolute Error : 4.10859483455688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Experiment with different hyperparameters such as learning rate, number of trees, and tree depth to\n",
        "optimise the performance of the model. Use grid search or random search to find the best\n",
        "hyperparameters"
      ],
      "metadata": {
        "id": "7nB5d6CLpnbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:-"
      ],
      "metadata": {
        "id": "sTnfvreAppfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Generate sample data\n",
        "X, Y = make_regression(n_samples=1000, n_features=5, n_informative=3, noise=10, random_state=42)"
      ],
      "metadata": {
        "id": "we1tDkZ-pzzN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(X,Y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "7c5FKvo8p22G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR315tUxqCZe",
        "outputId": "b49da421-9acd-477c-84de-d632f895c3e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtest.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jct0YCm6qEbT",
        "outputId": "cfc9bd92-429e-49d5-b8ef-071b2239be27"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.5]\n",
        "}"
      ],
      "metadata": {
        "id": "tL6GWAmFqH9k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a gradient boosting regressor object\n",
        "gbm = GradientBoostingRegressor()\n",
        "\n",
        "# Create a grid search object\n",
        "grid_search = GridSearchCV(gbm, param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error',cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search object to the data\n",
        "grid_search.fit(xtrain, ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "wXUtv1QRqLD9",
        "outputId": "0bafddb5-a11f-46ee-c8ea-e1a20cc7932b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
              "             param_grid={'learning_rate': [0.01, 0.1, 0.5],\n",
              "                         'max_depth': [3, 5, 7],\n",
              "                         'n_estimators': [100, 200, 300]},\n",
              "             scoring='neg_mean_squared_error')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.5],\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 7],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
              "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.5],\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 7],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
              "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: GradientBoostingRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(n_estimators=200)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(n_estimators=200)</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org."
      ],
      "metadata": {
        "id": "RlciG6fHqOYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best hyperparameters and their corresponding score\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best score: \", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4W7312fqR6Z",
        "outputId": "49a95f41-a93d-448b-ab4b-35f4edfb853f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
            "Best score:  -162.2314046927429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance of the model on the test set\n",
        "y_pred = grid_search.predict(xtest)\n",
        "mse = mean_squared_error(ytest, y_pred)\n",
        "r2 = r2_score(ytest, y_pred)\n",
        "print(\"Mean squared error: \", mse)\n",
        "print(\"R-squared score: \", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiVTCug_qUVj",
        "outputId": "ade4474c-2657-4467-9ee1-4cf07ca3887c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error:  147.57550336105837\n",
            "R-squared score:  0.9474511682909937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What is a weak learner in Gradient Boosting?"
      ],
      "metadata": {
        "id": "wlSameReq48U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:-\n",
        "\n",
        "In Gradient Boosting, a weak learner, also known as a base learner or base model, is a simple and relatively low-performing machine learning model that is used as a building block in the ensemble. Weak learners are typically decision trees with limited depth, often referred to as \"stumps\" or \"shallow trees.\"\n",
        "\n",
        "The key characteristics of a weak learner are:\n",
        "\n",
        "1.Weak learners are intentionally kept simple and have limited complexity. For decision trees, this means they are shallow and have only a few levels or nodes.\n",
        "\n",
        "2.Weak learners individually may not perform well on the training data. They have limited ability to capture complex relationships in the data.\n",
        "\n",
        "3.Weak learners are designed to be biased towards the errors made by the current ensemble of models. They focus on the examples that are challenging to classify or predict correctly.\n",
        "\n",
        "The role of weak learners in Gradient Boosting is crucial. The algorithm combines the predictions of multiple weak learners in a sequential manner, with each learner aiming to correct the errors or residuals made by the previous ensemble. The cumulative effect of adding multiple weak learners is that the ensemble becomes a strong learner that can capture complex patterns and achieve high predictive accuracy.\n",
        "\n",
        "Gradient Boosting iteratively fits a weak learner to the residuals of the previous ensemble. The weak learner's job is to find patterns in the data that the ensemble has not yet captured. These patterns typically correspond to the remaining errors in the predictions. By focusing on the most challenging examples, the ensemble gradually reduces the errors and improves its overall performance."
      ],
      "metadata": {
        "id": "hMO2_ehmq8Nd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. What is the intuition behind the Gradient Boosting algorithm?"
      ],
      "metadata": {
        "id": "4u4sSFhtr1vs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:-\n",
        "\n",
        "The intuition behind the Gradient Boosting algorithm can be understood through a few key concepts that highlight how it builds a strong predictive model from a series of weak learners. Here’s a breakdown of the main ideas:\n",
        "\n",
        "1.Learning from Mistakes:\n",
        "\n",
        "The core idea of Gradient Boosting is to learn from the errors made by previous models. Instead of training a single complex model, Gradient Boosting builds a series of simpler models (weak learners) that focus on correcting the mistakes of the models that came before them.\n",
        "\n",
        "2.Sequential Model Building:\n",
        "\n",
        "Gradient Boosting constructs models sequentially. Each new model is trained to predict the residuals (the differences between the actual values and the predictions of the current ensemble). This means that each model is specifically designed to improve upon the predictions made by the previous models.\n",
        "\n",
        "3.Gradient Descent Analogy:\n",
        "\n",
        "The term \"gradient\" in Gradient Boosting comes from the idea of using gradient descent to minimize a loss function. In this context, the loss function measures how well the model is performing. By fitting new models to the gradients (or slopes) of the loss function, Gradient Boosting effectively moves in the direction that reduces the error the most.\n",
        "\n",
        "4.Combining Weak Learners:\n",
        "\n",
        "Each weak learner (often a shallow decision tree) is not very powerful on its own, but when combined, they can capture complex patterns in the data. The ensemble of these weak learners works together to create a strong predictive model. The final prediction is typically a weighted sum of the predictions from all the weak learners.\n",
        "\n",
        "5.Learning Rate:\n",
        "\n",
        "The learning rate is a crucial parameter in Gradient Boosting. It controls how much each new model contributes to the overall prediction. A smaller learning rate means that the model learns more slowly, which can lead to better generalization and performance, but it requires more iterations (more weak learners) to achieve good results.\n",
        "\n",
        "6.Flexibility and Adaptability:\n",
        "Gradient Boosting is flexible and can be adapted to various types of loss functions, making it suitable for different types of problems, such as regression and classification. This adaptability allows it to be used in a wide range of applications.\n",
        "\n",
        "Summary:\n",
        "\n",
        "In summary, the intuition behind Gradient Boosting is to build a strong predictive model by sequentially adding simple models that learn from the mistakes of their predecessors. By focusing on the errors and using a gradient descent-like approach to minimize the loss, Gradient Boosting effectively combines the strengths of many weak learners to create a robust and accurate model. This method allows it to capture complex relationships in the data while maintaining a manageable level of complexity."
      ],
      "metadata": {
        "id": "8zxqgDypr41u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. How does Gradient Boosting algorithm build an ensemble of weak learners?"
      ],
      "metadata": {
        "id": "TjsII1gHsmq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LqoaLsZIvLva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:-\n",
        "\n",
        "The Gradient Boosting algorithm builds an ensemble of weak learners in a sequential and iterative manner. At each iteration, the algorithm trains a new weak learner that can improve the accuracy of the current ensemble, and then adds it to the ensemble in a weighted manner.\n",
        "\n",
        "The general steps of the Gradient Boosting algorithm are:\n",
        "\n",
        "1.Initialize the ensemble by fitting a single weak learner (e.g., a decision tree) to the data and making a prediction based on the input features.\n",
        "\n",
        "2.Compute the difference between the predicted values and the true target values, which is called the residual.\n",
        "\n",
        "3.Train a new weak learner to predict the residual (i.e., the difference between the predicted and true values) instead of the original target variable. This new learner is fit to the negative gradient of the loss function with respect to the current predictions of the ensemble, which gives it a clear direction for improving the predictions.\n",
        "\n",
        "4.Add the new weak learner to the ensemble by combining it with the previous learners in a weighted manner. The weights of the previous learners are adjusted to give more weight to the models that made larger contributions to the prediction.\n",
        "\n",
        "5.Repeat steps 2-4 until a stopping criterion is met (e.g., a maximum number of iterations, a minimum improvement in accuracy, or the presence of overfitting)."
      ],
      "metadata": {
        "id": "mEyHshHXsp85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. What are the steps involved in constructing the mathematical intuition of Gradient Boosting\n",
        "algorithm?"
      ],
      "metadata": {
        "id": "WjPGz6QVt0oS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:-\n",
        "\n",
        "Understanding Gradient Boosting: A Step-by-Step Guide\n",
        "\n",
        "Gradient Boosting is a powerful machine learning technique used for both regression (predicting continuous values) and classification (predicting categories). Let’s break down the process into simple, easy-to-follow steps:\n",
        "\n",
        "1.Identify the Problem:\n",
        "\n",
        "First, clarify what you want to achieve. Are you trying to predict a number (regression) or classify items into categories (classification)? Knowing this\n",
        "will guide your approach.\n",
        "\n",
        "2.Choose a Loss Function:\n",
        "\n",
        "Next, select a loss function, which is a way to measure how well your model is performing. For regression tasks, you might use Mean Squared Error (MSE), while for classification tasks, Log Loss is a common choice. The loss function helps\n",
        "you understand how far off your predictions are from the actual values.\n",
        "\n",
        "3.Create an Initial Prediction:\n",
        "\n",
        "Start with a simple model to make your first predictions. This could be as straightforward as predicting the average of your target variable or using a basic linear regression model. This initial guess gives you a baseline to\n",
        "improve upon.\n",
        "\n",
        "4.Calculate the Errors:\n",
        "\n",
        "Now, look at how far off your initial predictions are. This is done by calculating the residuals, which are the differences between the actual values and your model’s predictions. These residuals highlight where your model needs improvement.\n",
        "\n",
        "5.Train a New Model on the Errors:\n",
        "\n",
        "With the residuals in hand, it’s time to train a new model specifically to predict these errors. Typically, a decision tree is used here, and it’s often kept shallow (limited depth) to ensure it captures the essential patterns without overfitting.\n",
        "\n",
        "6.Update Your Predictions:\n",
        "\n",
        "Add the predictions from this new model to your previous predictions. This step is where the \"boosting\" happens—you're enhancing your model by correcting its previous mistakes. You can control how much you adjust your predictions using a learning rate, which is a small number that determines the contribution of the new model.\n",
        "\n",
        "7.Repeat the Process:\n",
        "\n",
        "Keep repeating the steps of calculating errors, training new models, and updating predictions until your model converges or you reach a stopping point. This could be a set number of models, a minimal improvement in the loss function, or a maximum depth for the decision trees.\n",
        "\n",
        "8.Make Final Predictions:\n",
        "\n",
        "Once you’ve completed the training process, you can use your final model to make predictions on new data. This model should now be much more accurate than your initial guess!\n",
        "\n",
        "In Summary:\n",
        "\n",
        "Gradient Boosting is all about iteratively improving your model. By continuously adding new models that learn from the errors of previous ones, you create a strong predictive tool. This process continues until you achieve a model that performs well on your data."
      ],
      "metadata": {
        "id": "nnY24bOEt1GC"
      }
    }
  ]
}